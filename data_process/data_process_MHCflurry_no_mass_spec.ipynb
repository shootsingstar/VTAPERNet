{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "def from_ic50(ic50, max_ic50=50000.0):\n",
    "    \"\"\"\n",
    "    Convert ic50s to regression targets in the range [0.0, 1.0].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ic50 : numpy.array of float\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array of float\n",
    "    \"\"\"\n",
    "    x = 1.0 - (np.log(np.maximum(ic50, 1e-12)) / np.log(max_ic50))\n",
    "    \n",
    "    return np.minimum(\n",
    "        1.0,\n",
    "        np.maximum(0.0, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../original_data/mhcflurry_test_no_mass_spec/test.csv')\n",
    "df_curated = pd.read_csv('../original_data/curated_training_data.no_mass_spec.csv')\n",
    "df_STDbenchmark = pd.read_csv('../original_data/STDbenchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no mhcflurry_test_no_mass_spec data is included in the Training dataset\n",
    "df_merge = pd.merge(\n",
    "    df_curated[['allele', 'peptide']],\n",
    "    df_test[['allele', 'peptide']],\n",
    "    how='inner',\n",
    "    on=['allele', 'peptide']\n",
    ")\n",
    "\n",
    "df_train_val = df_curated[~df_curated[['allele', 'peptide']].apply(tuple, 1).isin(df_merge.apply(tuple, 1))]\n",
    "df_train_val = df_train_val.drop_duplicates(keep=False)\n",
    "\n",
    "# Ensure no STDbenchmark data is included in the Training dataset\n",
    "df_merge = pd.merge(\n",
    "    df_train_val[['allele', 'peptide']],\n",
    "    df_STDbenchmark[['allele', 'Description']],\n",
    "    how='inner',\n",
    "    left_on=['allele', 'peptide'],\n",
    "    right_on=['allele', 'Description']\n",
    ")\n",
    "\n",
    "df_train_val = df_train_val[~df_train_val[['allele', 'peptide']].apply(tuple, 1).isin(df_merge.apply(tuple, 1))]\n",
    "df_train_val = df_train_val.drop_duplicates(keep=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.iloc[:,:-2]\n",
    "df_test['pep_len'] = df_test['peptide'].apply(len)\n",
    "\n",
    "\n",
    "#Remove entries with measurement values ​​greater than 50,000\n",
    "df_test_processed = df_test.drop(index=(df_test.loc[(df_test['measurement_value'] > 50000)].index))\n",
    "\n",
    "#Only keep data whose \"measurement inequality\" is \"=\"\n",
    "df_test_processed = df_test_processed.drop(index=(df_test_processed.loc[(df_test_processed['measurement_inequality']== '>' )].index))\n",
    "df_test_processed = df_test_processed.drop(index=(df_test_processed.loc[(df_test_processed['measurement_inequality']== '<' )].index))\n",
    "\n",
    "#Data normalization\n",
    "df_test_processed[\"Normalized_QM\"] = df_test_processed[\"measurement_value\"].apply(from_ic50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset by allele\n",
    "test_dir = '../processed_data/mhcflurry_test_no_mass_spec/data'\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "for name, group in df_test_processed.groupby('allele') :\n",
    "    if 'HLA' in name:\n",
    "        name = name.replace('/', '&')\n",
    "        name = name.replace('*','_')\n",
    "        name = name.replace(':','')\n",
    "        pd.DataFrame(group).to_csv(os.path.join(test_dir,name+'.csv'),index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the length of polypeptides in each row and record them in the \"pep len\" column\n",
    "df_train_val['pep_len'] = df_train_val['peptide'].apply(len)\n",
    "\n",
    "#Filter out data with measurement_value <= 50000\n",
    "df_train_val_processed = df_train_val[df_train_val['measurement_value'] <= 50000]\n",
    "\n",
    "#Filter out data whose measurement_inequality is \"=\"\n",
    "df_train_val_processed = df_train_val_processed[df_train_val_processed['measurement_inequality'] == '=']\n",
    "\n",
    "#Data normalization\n",
    "df_train_val_processed[\"Normalized_QM\"] = df_train_val_processed[\"measurement_value\"].apply(from_ic50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset by allele\n",
    "trainval_dir = '../processed_data/mhcflurry_training_no_mass_spec/data'\n",
    "out_file = '../processed_data/mhcflurry_training_no_mass_spec/data'\n",
    "\n",
    "paths = [trainval_dir, out_file]\n",
    "for path in paths:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "for name, group in df_train_val_processed.groupby('allele') :\n",
    "    if 'HLA' in name:\n",
    "        name = name.replace('/', '&')\n",
    "        name = name.replace('*','_')\n",
    "        name = name.replace(':','')\n",
    "        pd.DataFrame(group).to_csv(os.path.join(trainval_dir,name+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove redundancy from each allele data set\n",
    "#The rule is: if there are 2 redundant data, take the maximum measurement value. If there are 3 or more redundant data, the median value is taken (measurement_value is larger).\n",
    "for file in os.listdir(trainval_dir):\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(trainval_dir,file),index_col=0)\n",
    "    #Remove duplicates and take the median value\n",
    "    #Sort by peptide column\n",
    "    df.sort_values(by='peptide',axis=0,ascending='True', inplace=True)\n",
    "    df = df.reset_index(drop = True)\n",
    "    df_uniq = pd.DataFrame(columns = ['peptide','measurement_value'])\n",
    "\n",
    "    #Get the median of all repeated peptides and their measurements\n",
    "    j = 1\n",
    "\n",
    "    for i in range(0, len(df)):\n",
    "        if(i == 0 or df['peptide'][i] != df['peptide'][i-1]):\n",
    "            df_tmp = df[df['peptide'] == df['peptide'][i]]\n",
    "\n",
    "            if(len(df_tmp) > 0):\n",
    "                df_tmp.sort_values(by='measurement_value',axis=0,ascending='True', inplace=True)\n",
    "                df_tmp = df_tmp.reset_index(drop = True)\n",
    "               \n",
    "                #Even number case:\n",
    "                if (len(df_tmp)%2) == 0 :\n",
    "                    index = math.ceil(len(df_tmp) / 2)\n",
    "                #Odd cases:\n",
    "                else:\n",
    "                    index = math.ceil(len(df_tmp) / 2) - 1    \n",
    "\n",
    "                measurement = df_tmp['measurement_value'][index]\n",
    "                df_uniq = df_uniq.append({'peptide':df['peptide'][i],'measurement_value':measurement}, ignore_index=True)\n",
    "\n",
    "    df = df.drop_duplicates(subset = ['peptide'], keep = 'first')\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    #Reconfirm. Find the same peptide and corresponding measurement_value in df as df_unique\n",
    "    for i in range(0, len(df_uniq)):\n",
    "        df.loc[df['peptide'] == df_uniq['peptide'][i], ['measurement_value']] = df_uniq['measurement_value'][i]\n",
    "\n",
    "    df.to_csv(os.path.join(out_file,file),index=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../processed_data/mhcflurry_test_no_mass_spec/data'\n",
    "trainval_dir = '../processed_data/mhcflurry_training_no_mass_spec/data'\n",
    "trainval_dir_new = '../processed_data/mhcflurry_training_no_mass_spec/data'\n",
    "\n",
    "paths = [test_dir, trainval_dir, trainval_dir_new]\n",
    "for path in paths:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "for file in os.listdir(test_dir):\n",
    "    df_tv = pd.read_csv(os.path.join(trainval_dir,file))\n",
    "    df_t = pd.read_csv(os.path.join(test_dir,file))\n",
    "\n",
    "    # C intersection T\n",
    "    df_m= pd.merge(df_tv,df_t,how=\"inner\")\n",
    "    #train = C-(C intersection T)\n",
    "    df_tv = pd.concat([df_tv,df_m],sort=False)\n",
    "    df_tv = df_tv.drop_duplicates(keep=False)  \n",
    "    \n",
    "    df_tv.to_csv(os.path.join(trainval_dir_new,file),index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical training set after duplication removal were counted.\n",
    "Allele_dir = '../processed_data/mhcflurry_training_no_mass_spec/data'\n",
    "\n",
    "files = os.listdir(Allele_dir)\n",
    "statistic = []\n",
    "for file in files:\n",
    "    Allele = file.split('.')[0]\n",
    "    df = pd.read_csv(os.path.join(Allele_dir,file))\n",
    "    pep_num = len(df)\n",
    "    pep_len_min = min(map(len,df['peptide']))\n",
    "    pep_len_max = max(map(len,df['peptide']))\n",
    "    QM_min = min(df['measurement_value'])\n",
    "    QM_max = max(df['measurement_value'])\n",
    "\n",
    "    statistic.append([Allele,pep_num,pep_len_min,pep_len_max,QM_min,QM_max])\n",
    "\n",
    "\n",
    "df_stt = pd.DataFrame(statistic,columns=['allele','pep_num','pep_len_min','pep_len_max','QM_min','QM_max'])\n",
    "df_stt.sort_values(by='allele',axis=0,ascending=True, inplace=True)\n",
    "df_stt = df_stt.reset_index(drop = True)\n",
    "df_stt.to_csv('../processed_data/mhcflurry_training_no_mass_spec/statistics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical test set\n",
    "Allele_dir = '../processed_data/mhcflurry_test_no_mass_spec/data'\n",
    "\n",
    "files = os.listdir(Allele_dir)\n",
    "statistic = []\n",
    "for file in files:\n",
    "    Allele = file.split('.')[0]\n",
    "    df = pd.read_csv(os.path.join(Allele_dir,file))\n",
    "\n",
    "    pep_num = len(df)\n",
    "    pep_len_min = min(map(len,df['peptide']))\n",
    "    pep_len_max = max(map(len,df['peptide']))\n",
    "    QM_min = min(df['measurement_value'])\n",
    "    QM_max = max(df['measurement_value'])\n",
    "\n",
    "    statistic.append([Allele,pep_num,pep_len_min,pep_len_max,QM_min,QM_max])\n",
    "\n",
    "\n",
    "df_stt = pd.DataFrame(statistic,columns=['allele','pep_num','pep_len_min','pep_len_max','QM_min','QM_max'])\n",
    "df_stt.sort_values(by='allele',axis=0,ascending=True, inplace=True)\n",
    "df_stt = df_stt.reset_index(drop = True)\n",
    "df_stt.to_csv('../processed_data/mhcflurry_test_no_mass_spec/statistics.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
